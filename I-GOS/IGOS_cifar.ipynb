{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31435607",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "import scipy.io as scio\n",
    "import datetime\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab\n",
    "import os\n",
    "import csv\n",
    "from skimage import transform, filters\n",
    "from textwrap import wrap\n",
    "import cv2\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import sys\n",
    "import matplotlib as mpl\n",
    "#mpl.use('Agg')\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from typing import Tuple\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a24cb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "igos' utils.py file is successfully imported\n"
     ]
    }
   ],
   "source": [
    "# bring your colab code here, \n",
    "\n",
    "from IGos_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c80f8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i want you to clear up this code, start with the obvious parts\n",
    "\n",
    "def Get_blurred_img(img, model, Gaussian_param = [51, 50], use_cuda = 1):\n",
    "    ########################\n",
    "    # Generate blurred images as the baseline\n",
    "\n",
    "    # Parameters:\n",
    "    # -------------\n",
    "    # input_img: the original input image\n",
    "    # img_label: the classification target that you want to visualize (img_label=-1 means the top 1 classification label)\n",
    "    # model: the model that you want to visualize\n",
    "    # resize_shape: the input size for the given model\n",
    "    #\n",
    "    # \n",
    "\n",
    "    #output\n",
    "    # ----\n",
    "    # original_img: resized numpy image\n",
    "    # img:  - BGR -,   np.float32()/255\n",
    "    # blurred_img -BGR - np.float32()/255\n",
    "    # logitori: class score\n",
    "    ####################################################\n",
    "\n",
    "    \n",
    "    print(\"before the thing\", img.dtype, img.shape, img.min(), img.max())\n",
    "    \n",
    "    # img = np.float32(img) / 255\n",
    "   \n",
    "    \n",
    "    Kernelsize = Gaussian_param[0]\n",
    "    SigmaX = Gaussian_param[1]\n",
    "    blurred_img = cv2.GaussianBlur(img, (Kernelsize, Kernelsize), SigmaX)\n",
    "\n",
    "    img_torch = preprocess_image(img, use_cuda, require_grad = False)\n",
    "\n",
    "    ori_output = model(img_torch)\n",
    "\n",
    "    # compute the outputs for the original image and the blurred image\n",
    "    if use_cuda:\n",
    "        logitori = ori_output.data.cpu().numpy().copy().squeeze()\n",
    "    else:\n",
    "        logitori = ori_output.data.numpy().copy().squeeze()\n",
    "\n",
    "\n",
    "    return  img, blurred_img, logitori\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f2eaba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bm1/miniconda3/envs/I_GOS/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/home/bm1/miniconda3/envs/I_GOS/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "before the thing float32 (32, 32, 3) 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# input_path = './Images/'\n",
    "# if not os.path.exists(input_path):\n",
    "#     os.makedirs(input_path)\n",
    "\n",
    "\n",
    "output_path = './Results/VIDEO/'\n",
    "if not os.path.isdir(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "\n",
    "model = load_model_new(use_cuda=use_cuda, model_name='vgg19')  #\n",
    "\n",
    "#############################################\n",
    "# imgname  = \"ILSVRC2012_val_00001003.JPEG\"\n",
    "# input_img = input_path + imgname\n",
    "\n",
    "# Define a transform to convert images to tensors and normalize them\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor()\n",
    "                                ])\n",
    "\n",
    "# Load the CIFAR-10 training set\n",
    "trainset = torchvision.datasets.CIFAR10(root='~/data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "# Define class labels\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Get one batch (the first image)\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "\n",
    "\n",
    "input_img =  images.squeeze().permute(1,2,0).cpu().numpy()\n",
    "##############################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_label = -1\n",
    "\n",
    "img, blurred_img, logitori = Get_blurred_img(input_img, model,\n",
    "                                                Gaussian_param=[51, 50], use_cuda=use_cuda)\n",
    "\n",
    "\n",
    "# mask, upsampled_mask, imgratio, curvetop, curve1, curve2, category = Integrated_Mask(img, blurred_img, model,\n",
    "#                                                                                             img_label,\n",
    "#                                                                                             max_iterations=15,\n",
    "#                                                                                             integ_iter=20,\n",
    "#                                                                                             tv_beta=2,\n",
    "#                                                                                             l1_coeff=0.01 * 100,\n",
    "#                                                                                             tv_coeff=0.2 * 100,\n",
    "#                                                                                             size_init=28,\n",
    "#                                                                                             use_cuda=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df69d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d2d41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "I_GOS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
